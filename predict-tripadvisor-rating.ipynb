{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n"},{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\nimport datetime\nfrom datetime import datetime, timedelta\nimport re\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Reviews[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки."},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data"},{"metadata":{},"cell_type":"markdown","source":"## 1. Обработка NAN "},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')\ndata['Number of Reviews'].fillna(value=0, inplace=True)\ndata['Price Range'].fillna(value=0, inplace=True)\n#data['Cuisine Style'] = data['Cuisine Style'].fillna(value='Other', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Обработка признаков\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Restaurant_id'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\ndata['Restaurant_id']=pd.to_numeric(data['Restaurant_id'], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_dict={0:0, '$':1, '$$ - $$$':2, '$$$$':3}\ndata['Price Range'] = data['Price Range'].replace(to_replace=price_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_dummies=pd.get_dummies(data['City'], drop_first=True)\ndata = pd.concat([pd.DataFrame(data), cities_dummies], axis=1)\ndata.drop(columns='City', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine Style'] = data.apply(lambda x: x['Cuisine Style'].replace('[', '').replace(']', '').replace(\n    \"'\", '').replace(' ', '') if type(x['Cuisine Style']) != float else x['Cuisine Style'], axis=1)\ndata['cuisines_count'] = data['Cuisine Style'].str.split(',').str.len().fillna(1)\ncuisines = data['Cuisine Style'].str.get_dummies(\n    ',').sum().sort_values(ascending=False)\ntop_cuisines = [x for x in cuisines.index if cuisines[x] < 1000]\ndata = data.join(data['Cuisine Style'].str.get_dummies(\n    ',').drop(top_cuisines, axis=1), how='left')\ndata.drop(columns='Cuisine Style', inplace=True)\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews']=data['Reviews'].astype(str)\ndata['Reviews'] = data.apply(lambda x: x['Reviews'].replace('[[], []]', 'No reviews'), axis=1)\ndata['Reviews'] = data['Reviews'].apply(lambda x: x.replace(\n    '[[', ''))\ndata['Reviews'] = data['Reviews'].apply(lambda x: x.replace(\n    ']]', ''))\ndata['Reviews'] = data['Reviews'].apply(lambda x: x.replace(\n    '[', ''))\ndata['Reviews'] = data['Reviews'].apply(lambda x: x.replace(\n    ']', ''))\ndata['Reviews'] = data['Reviews'].apply(lambda x: str(x) if type(x) == list else x)\ntime_reviews = []\nfor item in data['Reviews']:\n    time_reviews.append(re.findall(r'(\\d\\d/\\d\\d/\\d\\d\\d\\d)', item))\nreviews = pd.DataFrame(time_reviews)\ndata['first_date_reviews'] = pd.to_datetime(reviews[0])\ndata['second_date_reviews']= pd.to_datetime(reviews[1])\ndata['difference_between_reviews_date'] = data['first_date_reviews']-data['second_date_reviews']\ndata['difference_between_reviews_date'].max()\ndata['difference_between_reviews_date'].fillna(value=pd.Timedelta(seconds=0), inplace=True)\ndata['difference_between_reviews_date']=(data['difference_between_reviews_date'] / np.timedelta64(1, 'D')).astype(int) \ndata.drop(columns=['first_date_reviews', 'second_date_reviews'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ID_TA']=data['ID_TA'].apply(lambda x: x.replace('d', ''))\ndata['ID_TA']=data['ID_TA'].astype(int)\ndf_selected = data[['Restaurant_id', 'Ranking', 'Rating', 'Price Range',\n                 'Number of Reviews', 'ID_TA', 'difference_between_reviews_date']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['Reviews'], axis=1, inplace=True)\ndata.drop(columns=['URL_TA'], axis=1, inplace=True)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# EDA \n"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n\n>Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Корреляция признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data.drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncorr = df_selected.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_selected.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    df_output.drop(['Restaurant_id'], axis = 1, inplace=True)\n    df_output['Number_of_Reviews_isNAN'] = pd.isna(df_output['Number of Reviews']).astype('uint8')\n    df_output['Number of Reviews'].fillna(value=0, inplace=True)\n    df_output['Price Range'].fillna(value=0, inplace=True)\n    df_output['Cuisine Style'].fillna(value='Other', inplace=True)\n    df_output['Reviews'].fillna(value='0000-00-00 00:00:00', inplace=True)\n    price_dict={0:0, '$':1, '$$ - $$$':2, '$$$$':3}\n    df_output['Price Range'] = df_output['Price Range'].replace(to_replace=price_dict)\n    cities_dummies=pd.get_dummies(df_output['City'], drop_first=True)\n    df_output = pd.concat([pd.DataFrame(df_output), cities_dummies], axis=1)\n    df_output.drop(columns='City', inplace=True)\n    df_output['Cuisine Style'] = df_output.apply(lambda x: x['Cuisine Style'].replace('[', '').replace(']', '').replace(\n        \"'\", '').replace(' ', '') if type(x['Cuisine Style']) != float else x['Cuisine Style'], axis=1)\n    df_output['cuisines_count'] = df_output['Cuisine Style'].str.split(',').str.len().fillna(1)\n    cuisines = df_output['Cuisine Style'].str.get_dummies(\n        ',').sum().sort_values(ascending=False)\n    top_cuisines = [x for x in cuisines.index if cuisines[x] < 1000]\n    df_output = df_output.join(df_output['Cuisine Style'].str.get_dummies(\n        ',').drop(top_cuisines, axis=1), how='left')\n    df_output.drop(columns='Cuisine Style', inplace=True)\n    df_output['Reviews']=df_output['Reviews'].astype(str)\n    df_output['Reviews'] = df_output.apply(lambda x: x['Reviews'].replace('[[], []]', 'No reviews'), axis=1)\n    df_output['Reviews'] = df_output['Reviews'].apply(lambda x: x.replace(\n        '[[', ''))\n    df_output['Reviews'] = df_output['Reviews'].apply(lambda x: x.replace(\n        ']]', ''))\n    df_output['Reviews'] = df_output['Reviews'].apply(lambda x: x.replace(\n        '[', ''))\n    df_output['Reviews'] = df_output['Reviews'].apply(lambda x: x.replace(\n        ']', ''))\n    df_output['Reviews'] = df_output['Reviews'].apply(lambda x: str(x) if type(x) == list else x)\n    time_reviews = []\n    for item in df_output['Reviews']:\n        time_reviews.append(re.findall(r'(\\d\\d/\\d\\d/\\d\\d\\d\\d)', item))\n    reviews = pd.DataFrame(time_reviews)\n    df_output['first_date_reviews'] = pd.to_datetime(reviews[0])\n    df_output['second_date_reviews']= pd.to_datetime(reviews[1])\n    df_output['difference_between_reviews_date'] = df_output['first_date_reviews']-df_output['second_date_reviews']\n    df_output['difference_between_reviews_date'].max()\n    df_output['difference_between_reviews_date'].fillna(value=pd.Timedelta(seconds=0), inplace=True)\n    df_output['difference_between_reviews_date']=(df_output['difference_between_reviews_date'] / np.timedelta64(1, 'D')).astype(int) \n    df_output.drop(columns=['first_date_reviews', 'second_date_reviews'], axis=1, inplace=True)\n    df_output['ID_TA']=df_output['ID_TA'].apply(lambda x: x.replace('d', ''))\n    df_output['ID_TA']=df_output['ID_TA'].astype(int)\n    df_output.drop(columns=['Reviews'], axis=1, inplace=True)\n    df_output.drop(columns=['URL_TA'], axis=1, inplace=True)\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler()\n    scaler.fit_transform(df_output)\n    return df_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}